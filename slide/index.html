<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Neural Network 101</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/blood.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement("link");
			link.rel = "stylesheet";
			link.type = "text/css";
			link.href = window.location.search.match(/print-pdf/gi) ? "css/print/pdf.css" : "css/print/paper.css";
			document.getElementsByTagName("head")[0].appendChild(link);
		</script>
		<style type="text/css">
			.reveal li { font-size: 0.9em; text-align: left; }
			.reveal p {font-size: 0.9em; }
			html.intro body {
				background:url("images/background.jpg");
				background-position:center;
				background-size: 100%;

			}
		</style>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-state="intro">
					<h2>Neural Network 101</h2>
				</section>

				<section data-state="intro">
					<h2>Introdução</h2>
				</section>

				<section data-state="intro">
					<!--<p>A Neural Network is an <strong>Universal Approximator</strong> or, to say with different words, a flexible function that autonomously adapts its behaviour to satisfy as much as possible the relation between the number[s] passed to it as parameter[s] and the number[s] expected to be returned as relative result[s].</p>-->
					<p> Uma rede neural é uma <b><i>Universal Approximator</i></b> ou, em outras palavras, uma função altamente flexível
					que, automaticamente, consegue adaptar seu comportamento de modo a satisfazer a relação entre os dados passados como
					parâmetros e os dados esperados como resultado relativo.</p>
				</section>

				<section data-state="intro">
					<h2>Neuron</h2>
					<img src="images/bio_neuron.png">
					<ul>
						<li>Inputs (Dendritos)</li>
						<li>Processador (Núcleo celular)</li>
						<li>Output (Axônio)</li>
					</ul>
				</section>

				<section data-state="intro">
					<img src="images/neuron_basic.png">
					<!--<p> The neuron accumulates all incoming inputs, multiply by respective weights and sum all results.
						If it's in a certain threshold, it fires an output. </p>-->
						<p>O neurônio armazena os inputs, multiplica pelos respectivos pesos (<strong>weights</strong>) e soma
						todos os resultados de cada operação. Se estiver dentro de um certo limite, ele libera o output.</p>
				</section>

				<section data-state="intro">
					<img src="images/neuron_basic_explained.png">
				</section>
				<section data-state="intro">
					<img src="images/neuron_basic_explained2.png">
				</section>
				<section data-state="intro">
					<img src="images/neuron_basic_explained3.png">
				</section>

				<section data-state="intro">
					<h2>Função de Ativação</h2>
				</section>
				<section data-state="intro">
					<img src="images/activation_function.png">
					<ul>
						<li>Usada para um comportamento <strong>não-linear</strong>.</li>
						<li> Recebe um input para normalizar o output (entre 0 e 1). </li>
						<li> Geralmente é uma função sigmóide. </li>
					</ul>
				</section>
				<section data-state="intro">
					<h2>Feedfoward Network</h2>
				</section>
				<section data-state="intro">
					<img src="images/feedfoward.png" width="550px">
					<!--<p>The output from input layer serves as an input for the next layer (hidden layer). It's repeated until reaching
					   the final layer (output layer).</p>-->
					<p>Os outputs da camada de input serve de input para as próximas camadas (camada escondida). Esse processo é repetio
					até atingir a última camada (camada de output).</p>
				</section>
				<section data-state="intro">
					<h3>Então como a RN aprende? TREINANDO!</h3>
				</section>
				<section data-state="intro">
					<h3>Algoritmo de <strong>Backpropagation</strong></h3>
				</section>
				<section data-state="intro">
					<h3>Etapas do algoritmo:</h3>
					<ul>
						<li>Input -> Output;</li>
						<li>Depois disso, ele ensina qual deveria ser o verdadeiro output;</li>
						<li>Ajusta os pesos de acordo com o output ideal;</li>
						<li>Começa da camada de output até a camada de input (caminho reverso);</li>
						<li>Então testa o mesmo input, mas agora com os pesos ajustados;</li>
						<li>Repete o processo até o delta entre o output ideal e o output da rede neural seja pequeno o suficiente.</li>
					</ul>
				</section>
				<section data-state="intro">
					<h2>Gradient Descent</h2>
				</section>
				<section data-state="intro">
					<img src="images/sgd_optimal.png">
					<ul>
						<li>Calcula a inclinação (<strong>slope</strong>) no na posição atual do X;</li>
						<li>Muda o X pela inclinação negativa (<strong>x = x - slope</strong>);</li>
						<li>Repete até a inclinação ser zero (<strong>slope == 0</strong>);</li>
					</ul>
				</section>
				<section data-state="intro">
					<h3>Problema: Poços locais</h3>
					<img src="images/sgd_local_min.png">
				</section>
				<section data-state="intro">
					<img src="images/sgd_rand.png">
				</section>
				<section data-state="intro">
					<h2>CODE TIME!</h2>
				</section>
				<section data-state="intro">
					<h3>Treinando para um XOR</h3>
					<table>
						<thead>
							<tr>
								<th>Input</th>
								<th>Input</th>
								<th>Output</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>0</td>
								<td>0</td>
								<td>0</td>
							</tr>
							<tr>
								<td>0</td>
								<td>1</td>
								<td>1</td>
							</tr>
							<tr>
								<td>1</td>
								<td>0</td>
								<td>1</td>
							</tr>
							<tr>
								<td>1</td>
								<td>1</td>
								<td>0</td>
							</tr>
						</tbody>
					</table>
				</section>
				<section data-state="intro">
					<pre><code class="hljs" data-trim contenteditable>
						var synaptic = require("synaptic");

						// Create layers
						var inputLayer = new synaptic.Layer(2);
						var hiddenLayer1 = new synaptic.Layer(4);
						var hiddenLayer2 = new synaptic.Layer(4);
						var outputLayer = new synaptic.Layer(1);

						// Create weights connections
						inputLayer.project(hiddenLayer1);
						hiddenLayer1.project(hiddenLayer2);
						hiddenLayer2.project(outputLayer);
					</code></pre>
				</section>
				<section data-state="intro">
					<pre><code class="hljs" data-trim contenteditable>
						// Assemble the network
						var myNetwork = new synaptic.Network({
						    input: inputLayer,
						    hidden: [
						        hiddenLayer1,
						        hiddenLayer2
						    ],
						    output: outputLayer
						});
					</code></pre>
				</section>
				<section data-state="intro">
					<pre><code class="hljs" data-trim contenteditable>
						// Defining our trainer
						var trainer = new synaptic.Trainer(myNetwork);
						var trainingSet = [
							{ input: [0, 0], output: [0] },
							{ input: [0, 1], output: [1] },
							{ input: [1, 0], output: [1] },
							{ input: [1, 1], output: [0] }
						      
						];
					</code></pre>
				</section>
				<section data-state="intro">
					<pre><code class="hljs" data-trim contenteditable>
						// Training!
						trainer.train(
						    trainingSet,
						    {
						        rate: .1, // Learning rate
						        iterations: 100000, // Maximum number of Iterations
						        error: .0000005, // Minimum error
						        shuffle: true, // Shuffled after every iter.
						        cost: synaptic.Trainer.cost.MSE, // Self-explained
						        log: 1 // console.log the error and iter
						    }
						);
					</code></pre>
				</section>
				<section data-state="intro">
					<pre><code class="hljs" data-trim contenteditable>
						// Test!
						console.log("[0, 0] => [" + myNetwork.activate([0, 0]) + "]");
						console.log("[0, 1] => [" + myNetwork.activate([0, 1]) + "]");
						console.log("[1, 0] => [" + myNetwork.activate([1, 0]) + "]");
						console.log("[1, 1] => [" + myNetwork.activate([1, 1]) + "]");
					</code></pre>
				</section>
				<section data-state="intro">
					<img src="images/screencast.gif">
				</section>
				<section data-state="intro">
					<h1>END</h1>
					<a href="http://github.com/jrflga">jrflga</a>
				</section>
			</div>
		</div>
		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				transition: "slide",
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
